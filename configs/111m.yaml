# Copyright 2023 Cerebras Systems.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# 111M parameter model trained for 20tpp. Configuration roughly matches
# the Cerebras-GPT 111M model except for the choice of dataset

# model params
trainer:
  init:
    # device: 'CPU'
    seed: 1
    backend: 
      backend_type: 'CPU'
      cluster_config:
        max_act_per_csx: 1
        num_csx: 1        
        mount_dirs:
         - /net/srinjoym-dev/srv/nfs/srinjoym-data/ws/giga_gpt/ #/path/to/code/location
         - /net/srinjoym-dev/srv/nfs/srinjoym-data/ws/giga_gpt/data/shakespeare/ #/path/to/data/location        
        python_paths:
         - /net/srinjoym-dev/srv/nfs/srinjoym-data/ws/giga_gpt/ #/path/to/code/location
        mgmt_address: 172.31.63.134:9000
    model:
      width: 24 #768
      depth: 3 #10
      max_position_embeddings: 2048
      heads: 6 #12
      vocab_size: 50257
      dropout: 0.0
      bias: True
      init_std: 0.02
    model_dir: 'out_dir/'
    loop:
      num_steps: 1000 #9037
    checkpoint:
      steps: 100 #1000
    precision:
      precision_opt_level: 1
      max_gradient_norm: 1.0
    optimizer:
      AdamW:
        learning_rate: 6.0e-4
        weight_decay: 0.1
        eps: 1.0e-8
    schedulers:
      SequentialLR:
        schedulers:
          - LinearLR:
              initial_learning_rate: 0.0
              end_learning_rate: 6.0e-4
              total_iters: 1500
          - CosineDecayLR:
              initial_learning_rate: 6.0e-4
              end_learning_rate: 6.0e-5
              total_iters: 7537
        #milestones: [1500]    
    loggers:
      - TensorBoardLogger: {}  
    #callbacks:
    #  - ComputeNorm: {}
    #  - CheckLoss: {}
  fit:
    train_dataloader:
      #data_processor: GptHDF5MapDataProcessor # dummy value
      data_dir: /net/srinjoym-dev/srv/nfs/srinjoym-data/ws/giga_gpt/data/shakespeare/train.bin # replace this with the correct absolute path before running
      sequence_length: 100 #2048
      batch_size: 120      
      seed: 1    
  validate:
    val_dataloader:
      data_dir: /net/srinjoym-dev/srv/nfs/srinjoym-data/ws/giga_gpt/data/shakespeare/val.bin # replace this with the correct absolute path before running
      sequence_length: 100 #2048
      batch_size: 120      
      seed: 1
    # ckpt_path: /cb/home/srinjoym/ws/giga_gpt/out_dir/checkpoint_1000.mdl
